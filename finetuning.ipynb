{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport PIL.Image as Image\nimport tensorflow as tf\nimport json\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.layers import Dense, Concatenate, Dropout\nfrom tensorflow.keras import Model, Input\nfrom tensorflow.keras.callbacks import Callback\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras import layers\nfrom keras.layers import GlobalAveragePooling2D\n\nred_on_plat = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.3,\n    patience=3,\n    verbose=0,\n    mode='auto',\n    min_delta=0,\n    cooldown=0,\n    min_lr=0,\n)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor = 'val_loss',\n    min_delta = 0,\n    patience = 10,\n    verbose = 1,\n    mode = 'auto',\n    baseline = None,\n    restore_best_weights = False\n)\n\ndef degrees_to_radians(deg):\n    pi_on_180 = 0.017453292519943295\n    return deg * pi_on_180\n\ndef km_away(observation, prediction):    \n    obv_rad = tf.map_fn(degrees_to_radians, observation)\n    prev_rad = tf.map_fn(degrees_to_radians, prediction)\n    dlon_dlat = obv_rad - prev_rad \n    v = dlon_dlat / 2\n    v = tf.sin(v)\n    v = v ** 2\n    a = v[:,1] + tf.cos(obv_rad[:,1]) * tf.cos(prev_rad[:,1]) * v[:,0] \n    c = tf.sqrt(a)\n    c = 2 * tf.math.asin(c)\n    c = c * 6378.1\n    final = tf.reduce_sum(c)\n    final = final/tf.dtypes.cast(tf.shape(observation)[0], dtype= tf.float32)\n    return final","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-10T00:07:55.656331Z","iopub.execute_input":"2023-07-10T00:07:55.65669Z","iopub.status.idle":"2023-07-10T00:08:04.188462Z","shell.execute_reply.started":"2023-07-10T00:07:55.65666Z","shell.execute_reply":"2023-07-10T00:08:04.187506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEIGHT = 256\nWIDTH = 1024\nNUM_CLASSES = 12017 # CHANGE TO NUMBER OF CELLS\n\ndef data_augmentation(image):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.1)\n    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n    image = tf.image.random_hue(image, max_delta=0.02)\n    return image\n\ndef process_path_labels(dir_paths):\n    image_paths = []\n    output1_list = []\n    output2_list = []\n\n    for dir_path in tqdm(dir_paths, desc=\"Processing paths\"):\n        img_path = os.listdir(dir_path)[0]\n        img_path = os.path.join(dir_path, img_path)\n\n        output1 = np.zeros(NUM_CLASSES)  \n        output2 = np.zeros(2)\n\n        path_info = dir_path.split('/')[-1].split(',')\n        output1[int(path_info[0])] = 1\n        output2 = np.array([float(path_info[1]), float(path_info[2])])\n\n        output1_list.append(output1)\n        output2_list.append(output2)\n        image_paths.append(img_path)\n    return image_paths, output1_list, output2_list\n\ndef parse_image(filename):\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(image, channels=3)\n    return image\n\ndef process_image_and_label(filename, label1, label2):\n    image = parse_image(filename)\n    image = data_augmentation(image)\n    return image, (label1, label2)\n\ndef load_and_preprocess_data(image_paths, output1, output2):\n    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n    label1_dataset = tf.data.Dataset.from_tensor_slices(output1)\n    label2_dataset = tf.data.Dataset.from_tensor_slices(output2)\n\n    dataset = tf.data.Dataset.zip((image_dataset, label1_dataset, label2_dataset))\n    dataset = dataset.map(process_image_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset\n\ndef prepare_for_training(ds, cache=False, shuffle_buffer_size=5000, batch_size=256):\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n    ds = ds.repeat()\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2023-07-10T00:08:04.190014Z","iopub.execute_input":"2023-07-10T00:08:04.190751Z","iopub.status.idle":"2023-07-10T00:08:04.207832Z","shell.execute_reply.started":"2023-07-10T00:08:04.190716Z","shell.execute_reply":"2023-07-10T00:08:04.206875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.TPUStrategy(tpu)\nwith tpu_strategy.scope():\n    model = tf.keras.models.load_model('/kaggle/input/500k-model/500k_25_Model', custom_objects={'km_away': km_away})\n\n    gap = model.get_layer('Grid').output\n\n    for layer in model.layers:\n        layer.trainable = False\n\n    dense_2 =  Dense(250,name='mid_layer')(gap)\n    drop = Dropout(0.5)(dense_2)\n    dense_3 =  Dense(200,name='mid_layer_1')(drop)\n    dense_4 =  Dense(150,name='mid_layer_2')(dense_3)\n\n    dense_7 =  Dense(100,kernel_regularizer='l2',name='mid_layer_3')(dense_4)\n    dense_8 =  Dense(80,kernel_regularizer='l2',name='mid_layer_4')(dense_7)\n    drop = Dropout(0.5)(dense_8)\n    dense_11 = Dense(50,kernel_regularizer='l2',name='mid_layer_5')(drop)\n    out_2 =  Dense(2,activation='linear',name='Coords')(dense_11)\n\n    new_model = tf.keras.Model(inputs=model.input, outputs=[model.output, out_2])\n\n    with tf.keras.utils.custom_object_scope({'km_away': km_away}):\n        new_model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001), loss={'Grid': None, 'Coords': 'mae'}, metrics={'Grid': None, 'Coords': km_away})\n        \n    print('Model compiled.')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_path = '/kaggle/input/500k-images/500k_world'  # CHANGE TO RIGHT DIRECTORY\n\njson_file = '/kaggle/input/500k-split/500k_split.json' # preprocessed paths CHANGE TO RIGHT PATH\nwith open(json_file, 'r') as infile:\n    data_dict = json.load(infile)\n    \ntrain_paths = data_dict['train_paths']\nval_paths = data_dict['val_paths']\ntest_paths = data_dict['test_paths']","metadata":{"execution":{"iopub.status.busy":"2023-07-10T00:08:04.238606Z","iopub.execute_input":"2023-07-10T00:08:04.238892Z","iopub.status.idle":"2023-07-10T00:08:04.261415Z","shell.execute_reply.started":"2023-07-10T00:08:04.238868Z","shell.execute_reply":"2023-07-10T00:08:04.260532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('starting image processing')\nimage_paths_train, output1_train, output2_train = process_path_labels(train_paths)\nprint('train processed')\nimage_paths_val, output1_val, output2_val = process_path_labels(val_paths)\nprint('val processed')\n\ntrain_ds = load_and_preprocess_data(image_paths_train, output1_train, output2_train)\nprint('train loaded')\nval_ds = load_and_preprocess_data(image_paths_val, output1_val, output2_val)\nprint('val loaded')\n\nbatch_size = 256\ntrain_ds = prepare_for_training(train_ds, batch_size=batch_size)\nprint('train prepared')\nval_ds = prepare_for_training(val_ds, batch_size=batch_size)\nprint('finished image processing')","metadata":{"execution":{"iopub.status.busy":"2023-07-10T00:08:04.262918Z","iopub.execute_input":"2023-07-10T00:08:04.263274Z","iopub.status.idle":"2023-07-10T00:08:24.676954Z","shell.execute_reply.started":"2023-07-10T00:08:04.263241Z","shell.execute_reply":"2023-07-10T00:08:24.676012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history_classifier = new_model.fit(train_ds, steps_per_epoch=len(train_paths)//batch_size, epochs=25, validation_data=val_ds, validation_steps=len(val_paths)//batch_size, callbacks=[red_on_plat, early_stop])\nnew_model.save('500k_finetuned')\nnew_model.save_weights('500k_finetuned_weights', save_format = 'tf')\n\nhist_df = pd.DataFrame(history_classifier.history) \nhist_df.to_csv('history_classifier.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-10T00:08:24.678467Z","iopub.execute_input":"2023-07-10T00:08:24.678823Z","iopub.status.idle":"2023-07-10T01:28:11.188698Z","shell.execute_reply.started":"2023-07-10T00:08:24.678791Z","shell.execute_reply":"2023-07-10T01:28:11.187686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Evaluation')\n\nimage_paths_test, output1_test, output2_test = process_path_labels(test_paths) \ntest_ds = load_and_preprocess_data(image_paths_test, output1_test, output2_test) \n\ndef prepare_for_testing(ds, batch_size=256):\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return ds\n\ntest_ds = prepare_for_testing(test_ds)\n\nresults = new_model.evaluate(test_ds)","metadata":{"execution":{"iopub.status.busy":"2023-07-10T01:28:11.190544Z","iopub.execute_input":"2023-07-10T01:28:11.190938Z","iopub.status.idle":"2023-07-10T01:28:11.198209Z","shell.execute_reply.started":"2023-07-10T01:28:11.190904Z","shell.execute_reply":"2023-07-10T01:28:11.1972Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n!pip install kecam --target=/kaggle/working/mysitepackages\nsys.path.append('/kaggle/working/mysitepackages')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport PIL.Image as Image\nimport tensorflow as tf\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom tensorflow.keras.layers import Dense, Concatenate, Dropout\nfrom tensorflow.keras import Model, Input\nfrom tensorflow.keras.callbacks import Callback\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import LearningRateScheduler\nfrom tensorflow.keras import layers\nfrom keras_cv_attention_models import tinyvit\nfrom keras_cv_attention_models import efficientnet\nfrom keras.layers import GlobalAveragePooling2D\n\nred_on_plat = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.5,\n    patience=3,\n    verbose=0,\n    mode='auto',\n    min_delta=0,\n    cooldown=0,\n    min_lr=0,\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEIGHT = 256\nWIDTH = 1024\nNUM_CLASSES = 12017 # CHANGE TO NUMBER OF CELLS\n\ndef data_augmentation(image):\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.1)\n    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n    image = tf.image.random_hue(image, max_delta=0.02)\n    return image\n\ndef process_path_labels(dir_paths):\n    image_paths = []\n    output1_list = []\n    for dir_path in dir_paths:\n        img_path = os.listdir(dir_path)[0]\n        img_path = os.path.join(dir_path, img_path)\n\n        output1 = np.zeros(NUM_CLASSES) \n\n        path_info = dir_path.split('/')[-1].split(',')\n        output1[int(path_info[0])] = 1\n\n        output1_list.append(output1)\n\n        image_paths.append(img_path)\n    return image_paths, output1_list \n\ndef parse_image(filename):\n    image = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(image, channels=3)\n    return image\n\ndef process_image_and_label(filename, label):\n    image = parse_image(filename)\n    image = data_augmentation(image)\n    return image, label\n\ndef load_and_preprocess_data(image_paths, output1): \n    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n    label1_dataset = tf.data.Dataset.from_tensor_slices(output1)\n\n    dataset = tf.data.Dataset.zip((image_dataset, (label1_dataset))) \n    dataset = dataset.map(process_image_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n    return dataset\n\ndef prepare_for_training(ds, cache=False, shuffle_buffer_size=5000, batch_size=256):\n    if cache:\n        if isinstance(cache, str):\n            ds = ds.cache(cache)\n        else:\n            ds = ds.cache()\n    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n    ds = ds.repeat()\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return ds\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def initialize_model(inp_shape=(HEIGHT,WIDTH,3),out_1_shape=(NUM_CLASSES),weights_initial='imagenet',trainable=True,feature_model=InceptionResNetV2):\n    print('Initialising Network')\n    input_layer = Input(shape=inp_shape)\n    \n    feature_extraction = feature_model(include_top=False,weights=weights_initial,input_shape=inp_shape,pooling='avg',input_tensor=input_layer)\n    feature_extraction.trainable = trainable\n\n    embed = feature_extraction.output\n    \n    out_1 = Dense(out_1_shape,activation='softmax',name='Grid')(embed)\n    \n    model = Model(inputs=input_layer,outputs=out_1)\n        \n    # model.summary()\n    print('Network Initialised and compiled. Input shape: {}, Output shape: {}'.format(model.input_shape,model.output_shape))\n    print('Loss: Categorical Cross Entropy')\n    return model\n\n\"\"\"def initialize_model():\n    input_layer = tf.keras.Input(shape=(HEIGHT, WIDTH, 3))\n    \n    feature_extraction = tinyvit.TinyViT_21M(input_shape=(HEIGHT, WIDTH, 3), num_classes=0, pretrained='imagenet21k-ft1k')(input_layer)\n    feature_extraction.trainable = True\n    \n    gap = GlobalAveragePooling2D()(feature_extraction) \n    out_1 = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', name='Grid')(gap)\n    \n    model = tf.keras.Model(inputs=input_layer, outputs=out_1)\n    print('Model initialized.')\n    return model\"\"\"\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_path = '/kaggle/input/500k-images/500k_world'  # CHANGE TO RIGHT DIRECTORY\njson_file = '/kaggle/input/500k-split/500k_split.json' # preprocessed paths CHANGE TO RIGHT PATH\nwith open(json_file, 'r') as infile:\n    data_dict = json.load(infile)\n    \ntrain_paths = data_dict['train_paths']\nval_paths = data_dict['val_paths']\ntest_paths = data_dict['test_paths']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Preparing for images for training.')\nbatch_size = 256\nimage_paths_train, output1_train = process_path_labels(train_paths)\nimage_paths_val, output1_val = process_path_labels(val_paths)\n\ntrain_ds = load_and_preprocess_data(image_paths_train, output1_train)\nval_ds = load_and_preprocess_data(image_paths_val, output1_val)\n\ntrain_ds = prepare_for_training(train_ds, batch_size=batch_size)\nval_ds = prepare_for_training(val_ds, batch_size=batch_size)\nprint('Finished image preparation.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect('local')\ntpu_strategy = tf.distribute.TPUStrategy(tpu)\nwith tpu_strategy.scope():\n    model = initialize_model()\n    model.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.001), \n                  loss=tf.keras.losses.CategoricalCrossentropy(), \n                  metrics=['accuracy'])\n\nhistory_classifier = model.fit(train_ds, steps_per_epoch=len(train_paths)//batch_size, epochs=10, validation_data=val_ds, validation_steps=len(val_paths)//batch_size, callbacks=[red_on_plat])\nmodel.save('500k_1_Model')\nmodel.save_weights('500k_weights.h5')\n\nhist_df = pd.DataFrame(history_classifier.history) \nhist_df.to_csv('history_classifier.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"print('Evaluation')\n\nimage_paths_test, output1_test = process_path_labels(test_paths) \ntest_ds = load_and_preprocess_data(image_paths_test, output1_test) \n\ndef prepare_for_testing(ds, batch_size=256):\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return ds\n\ntest_ds = prepare_for_testing(test_ds, batch_size=256)\n\n# Evaluate model:\ntest_loss, test_accuracy = model.evaluate(test_ds)\nprint(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}